{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e484a86f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_dataset' from 'datasets' (C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\datasets\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_dataset' from 'datasets' (C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\datasets\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from transformers import AdamW, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012eb71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repo = 'google/mt5-base'\n",
    "model_path = 'mt5_translation.pt'\n",
    "max_seq_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec05d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c57e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117b05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_TOKEN_MAPPING = {\n",
    "    'en': '<en>',\n",
    "    'fi': '<fi>'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ce9eb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(250102, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {'additional_special_tokens': list(LANG_TOKEN_MAPPING.values())}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582e6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_str(text, target_lang, tokenizer, seq_len,\n",
    "                     lang_token_map=LANG_TOKEN_MAPPING):\n",
    "  target_lang_token = lang_token_map[target_lang]\n",
    "\n",
    "  # Tokenize and add special tokens\n",
    "  input_ids = tokenizer.encode(\n",
    "      text = target_lang_token + text,\n",
    "      return_tensors = 'pt',\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      max_length = seq_len)\n",
    "\n",
    "  return input_ids[0]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38cb285e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path,map_location = torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90d1a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(input_text1,output_language1):\n",
    "    input_ids = encode_input_str(\n",
    "    text = input_text1,\n",
    "    target_lang = output_language1,\n",
    "    tokenizer = tokenizer,\n",
    "    seq_len = model.config.max_length,\n",
    "    lang_token_map = LANG_TOKEN_MAPPING)\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "\n",
    "    output_tokens = model.generate(input_ids, num_beams=20, length_penalty=0.2)\n",
    "    print(\"TRANSLATION:\")\n",
    "    print(input_text1 + '  ->  ' + tokenizer.decode(output_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b545f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "456fce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(im_path):\n",
    "    dpi = 80\n",
    "    im_data = plt.imread(im_path)\n",
    "\n",
    "    height, width  = im_data.shape[:2]\n",
    "    \n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1b5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_borders(image):\n",
    "    newImage = image.copy()\n",
    "    gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)\n",
    "    contours, heiarchy = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntsSorted = sorted(contours, key=lambda x:cv2.contourArea(x))\n",
    "    cnt = cntsSorted[-1]\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    crop = image[y:y+h, x:x+w]\n",
    "    return (crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2af2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffb6e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audiopath1,output_language1):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(audiopath1) as source:\n",
    "        audio_data = r.record(source)\n",
    "        text = r.recognize_google(audio_data,language=output_language1)\n",
    "        return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4db73af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for image, 2 for text or 3 for audio 2\n",
      "Enter sentence (less than 20 words): Olette typerä\n",
      "What is the output language?\n",
      "fi for finnish or en for english: en\n",
      "TRANSLATION:\n",
      "Olette typerä.  ->  You are stupid.\n"
     ]
    }
   ],
   "source": [
    "choice = input(\"Enter 1 for image, 2 for text or 3 for audio \")\n",
    "\n",
    "it_is = True\n",
    "try:\n",
    "    int(choice)\n",
    "    it_is = True\n",
    "except ValueError:\n",
    "    it_is = False\n",
    "    \n",
    "if it_is:\n",
    "    choice = int(choice)\n",
    "    \n",
    "    # For image input\n",
    "    if(choice==1):\n",
    "        imagepath = input(\"Enter image path(eg. 'IMG.jpg'): \")\n",
    "        \n",
    "        print(\"What is the output language?\")\n",
    "        output_language = input(\"fi for finnish or en for english: \")\n",
    "\n",
    "        if(output_language!='fi' and output_language!='en'):\n",
    "            print(\"Please enter only en or fi!\")\n",
    "            print(sys.exit())\n",
    "            \n",
    "        else:\n",
    "            img = cv2.imread(imagepath)\n",
    "            no_borders = remove_borders(img)\n",
    "            \n",
    "            if(output_language=='en'):\n",
    "                input_text = pytesseract.image_to_string(img,lang=\"fin\")\n",
    "            else:\n",
    "                input_text = pytesseract.image_to_string(img)\n",
    "                \n",
    "            input_text = input_text+'.'\n",
    "            display(imagepath)\n",
    "            translator(input_text,output_language)\n",
    "            \n",
    "    # For text input\n",
    "    elif(choice==2):\n",
    "        input_text = input(\"Enter sentence (less than 20 words): \")\n",
    "        input_text = input_text+'.'\n",
    "        \n",
    "        print(\"What is the output language?\")\n",
    "        output_language = input(\"fi for finnish or en for english: \")\n",
    "\n",
    "        if(output_language!='fi' and output_language!='en'):\n",
    "            print(\"Please enter only en or fi!\")\n",
    "            print(sys.exit())\n",
    "        else:\n",
    "            translator(input_text,output_language)\n",
    "            \n",
    "    # For audio input\n",
    "    elif(choice==3):\n",
    "        audiopath = input(\"Enter audio path(eg. 'audio.wav'): \")\n",
    "        \n",
    "        print(\"What is the output language?\")\n",
    "        output_language = input(\"fi for finnish or en for english: \")\n",
    "\n",
    "        if(output_language!='fi' and output_language!='en'):\n",
    "            print(\"Please enter only en or fi!\")\n",
    "            print(sys.exit())\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if(output_language=='en'):\n",
    "                input_text = audio_to_text(audiopath, 'fi')\n",
    "            else:\n",
    "                input_text = audio_to_text(audiopath,'en-GB')\n",
    "            input_text = input_text+'.'\n",
    "            translator(input_text,output_language)\n",
    "            \n",
    "    else:\n",
    "        print(\"Please enter 1,2 or 3 only!\")\n",
    "else:\n",
    "    print(\"Not a number!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853d9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a8e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54690e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb327f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
